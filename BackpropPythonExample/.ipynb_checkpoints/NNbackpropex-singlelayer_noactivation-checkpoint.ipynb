{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Example Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example has been adapted form the below blog post:\n",
    "\n",
    "https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "\n",
    "For the mathematical explaination read my blog post and neural network fundamentals series here:\n",
    "\n",
    "https://samzee.net/2019/02/20/neural-networks-learning-the-basics-backpropagation/\n",
    "\n",
    "The standard process for building the neural network is as follows:\n",
    "1. Initialize Network\n",
    "2. Forward Propagate\n",
    "3. Back Propagate Error\n",
    "4. Train Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce example in blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialze_network(n_input, n_hidden, n_output):\n",
    "    network = []\n",
    "    hidden_layer = {'weights': [np.random.rand(n_input,n_hidden) , np.random.rand(n_hidden)]}\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = {'weights': [np.random.rand(n_hidden,n_output) , np.random.rand(n_output)]}\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "#defines sigmoid function\n",
    "def sigmoid(x):\n",
    "    s = 1/(1 + np.exp(-x))\n",
    "    return s\n",
    "#derivative of the loss function delta rule\n",
    "def dloss(target, output):\n",
    "    error = -(target - output)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the network\n",
    "random.seed(1)\n",
    "network = initialze_network(2, 2, 2)\n",
    "weights = [neuron['weights'] for neuron in network]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing example\n",
    "x = np.array([[0.15,0.2],[0.25,0.3]])\n",
    "z = np.array([[0.4,0.45],[0.50,0.55]])\n",
    "inputs = np.array([0.05, 0.1])\n",
    "target = np.array([0.01, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update randomised inputs to fixed inputs\n",
    "weights[0][0] = x\n",
    "weights[1][0] = z\n",
    "weights[0][1] = np.array([0.35, 0.35]) #removed bias from the hidden layer\n",
    "weights[1][1] = np.array([0.6, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward pass\n",
    "def forward_pass(weights, inputs, bias):\n",
    "    a = np.dot(weights, inputs) + bias\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hidden = forward_pass(weights[0][0], inputs, weights[0][1])\n",
    "#activation\n",
    "a_hidden = sigmoid(a_hidden)\n",
    "#output\n",
    "outputs = forward_pass(weights[1][0], a_hidden, weights[1][1])\n",
    "#activation\n",
    "outputs = sigmoid(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the backward pass outputs\n",
    "def out_gradient(target, output, inputs):\n",
    "    gradient = (dloss(target, output)*output*(1- output))*inputs\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_gradient(target, output):\n",
    "    gradient = dloss(target, output)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = [out_gradient(target, outputs, item) for item in a_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08216704,  0.08266763],\n",
       "       [-0.02260254, -0.02274024]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output gradients\n",
    "gradients = np.vstack(grad).T\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_grad = bias_gradient(target, outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hidden layer back prop\n",
    "def hid_gradient(target, output, inputs, a, weight):\n",
    "    k = np.sum((-(target - output)*output*(1 - output))*weight) #the first column of a matrix\n",
    "    g = a*(1- a)*inputs\n",
    "    return g*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00043857, 0.00049913],\n",
       "       [0.00087464, 0.00099543]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply\n",
    "w = weights[1][0].T\n",
    "h_gradients = []\n",
    "for item in w:\n",
    "    grad = hid_gradient(target, outputs, inputs, a_hidden, item)\n",
    "    h_gradients.append(grad)\n",
    "mygrad = np.vstack(h_gradients).T\n",
    "mygrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the learning rate\n",
    "#update weights\n",
    "l = 0.5\n",
    "weights[0][0] = weights[0][0] - l*mygrad\n",
    "weights[1][0] = weights[1][0] - l*gradients\n",
    "weights[1][1] = weights[1][1] - 1*bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[0.14978072, 0.19975043],\n",
       "         [0.24956268, 0.29950229]]), array([0.35, 0.35])],\n",
       " [array([[0.35891648, 0.40866619],\n",
       "         [0.51130127, 0.56137012]]), array([-0.14136507,  0.81707153])]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialze_network(n_input, n_hidden, n_output):\n",
    "    network = []\n",
    "    hidden_layer = {'weights': [[np.random.rand(n_input,n_hidden)] , [0]]}\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = {'weights': [[np.random.rand(n_hidden,n_output)] , [random.random()]]}\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "#forward pass\n",
    "def forward_pass(weights, inputs, bias):\n",
    "    a = np.dot(weights, inputs) + bias\n",
    "    return a\n",
    "def out_gradient(target, output, inputs):\n",
    "    gradient = (dloss(target, output))*inputs\n",
    "    return gradient\n",
    "def bias_gradient(target, output):\n",
    "    gradient = dloss(target, output)\n",
    "    return gradient\n",
    "#one hidden layer back prop\n",
    "def hid_gradient(target, output, inputs, a, weight):\n",
    "    k = np.sum((-(target - output))*weight) #the first column of a matrix\n",
    "    g = a*(1- a)*inputs\n",
    "    return g*k\n",
    "\n",
    "#loss function\n",
    "def lossfunction(target,output):\n",
    "    loss = (1/2)*(target - output)**2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(network, inputs, target, l, n_epoch):\n",
    "    weights = [neuron['weights'] for neuron in network]\n",
    "    for epoch in range(n_epoch):\n",
    "        myloss = []\n",
    "        h_gradients = []\n",
    "        for i in range(len(inputs)):\n",
    "            a_hidden = forward_pass(weights[0][0][0], inputs[i], weights[0][1])\n",
    "            outputs = forward_pass(weights[1][0][0].T, a_hidden, weights[1][1])\n",
    "            loss = lossfunction(target[i], outputs)\n",
    "            t_loss = np.sum(loss)\n",
    "            myloss.append(t_loss)\n",
    "            grad = [out_gradient(target[i], outputs, item) for item in a_hidden]\n",
    "            #print(\"this is output gradient {} for iteration {}\".format(grad, i))\n",
    "            gradients = np.vstack(grad).T     #output gradients\n",
    "            bias_grad = bias_gradient(target[i], outputs) \n",
    "            w = np.array(weights[1][0]).T\n",
    "            for item in w:\n",
    "                grad = hid_gradient(target[i], outputs, inputs[i], a_hidden[0], item)\n",
    "                h_gradients.append(grad)\n",
    "                mygrad = np.vstack(h_gradients).T\n",
    "            weights[0][0] = weights[0][0] - l*mygrad\n",
    "            weights[1][0] = weights[1][0] - l*gradients\n",
    "            weights[1][1] = weights[1][1] - l*bias_grad\n",
    "            final_loss = np.sum(myloss)\n",
    "            #print('>epoch={}, error={}'.format(n_epoch, final_loss))\n",
    "            return final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training samples\n",
    "inputs = np.array([[2.7810836, 2.550537003], [1.465489372, 2.362125076], [396561688, 4.400293529], [1.38807019, 1.850220317],\n",
    "                  [3.06407232, 3.005305973],[7.627531214, 2.759262235],[5.332441248, 2.088626775],[6.922596716, 1.77106367],\n",
    "                  [8.675418651, 0.242068655], [7.673756466, 3.508563011]])\n",
    "target = np.array([[0], [0], [0], [0], [0], [1], [1], [1], [1], [1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset from:\n",
    "\n",
    "https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/\n",
    "\n",
    "An alternative implementation can also be accessed via this link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.03924003])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize network\n",
    "network = initialze_network(inputs.shape[1], 2, target.shape[1])\n",
    "weights = [neuron['weights'] for neuron in network]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samantha.vandermerwe\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning:\n",
      "\n",
      "overflow encountered in square\n",
      "\n",
      "c:\\users\\samantha.vandermerwe\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning:\n",
      "\n",
      "overflow encountered in multiply\n",
      "\n",
      "c:\\users\\samantha.vandermerwe\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning:\n",
      "\n",
      "overflow encountered in multiply\n",
      "\n",
      "c:\\users\\samantha.vandermerwe\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning:\n",
      "\n",
      "overflow encountered in double_scalars\n",
      "\n",
      "c:\\users\\samantha.vandermerwe\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in subtract\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epoch = [x for x in range(1, 100)]\n",
    "loss = []\n",
    "for n in n_epoch:\n",
    "    myloss = train_network(network, inputs, target, 0.5, n)\n",
    "    loss.append(myloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network works as we see the decrease in the loss function with each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(n_epoch[1:], loss[1:])\n",
    "#pyplot.plot(series_in, relu_out)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.059189892049436,\n",
       " 328021.1754328053,\n",
       " 6.061172458592693e+26,\n",
       " 2.4825846861480176e+117,\n",
       " inf,\n",
       " inf,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

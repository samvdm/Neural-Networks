{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Example Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example has been adapted form the below blog post:\n",
    "\n",
    "https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "\n",
    "For the mathematical explaination read my blog post and neural network fundamentals series here:\n",
    "\n",
    "https://samzee.net/2019/02/20/neural-networks-learning-the-basics-backpropagation/\n",
    "\n",
    "The standard process for building the neural network is as follows:\n",
    "1. Initialize Network\n",
    "2. Forward Propagate\n",
    "3. Back Propagate Error\n",
    "4. Train Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce example in blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialze_network(n_input, n_hidden, n_output):\n",
    "    network = []\n",
    "    hidden_layer = {'weights': [np.random.rand(n_input,n_hidden)]}\n",
    "    network.append(hidden_layer)\n",
    "    hidden_layer = {'weights': [np.random.rand(n_input,n_hidden)]}\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = {'weights': [np.random.rand(n_hidden,n_output)]}\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "#defines sigmoid function\n",
    "def sigmoid(x):\n",
    "    s = 1/(1 + np.exp(-x))\n",
    "    return s\n",
    "#derivative of the loss function delta rule\n",
    "def dloss(target, output):\n",
    "    error = -(target - output)\n",
    "    return error\n",
    "#forward pass\n",
    "def forward_pass(weights, inputs):\n",
    "    a = np.dot(weights, inputs)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the network\n",
    "random.seed(1)\n",
    "network = initialze_network(2, 2, 2)\n",
    "weights = [neuron['weights'] for neuron in network]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing example\n",
    "x = np.array([[0.01,0.2],[0.15,0.08]])\n",
    "y = np.array([[0.01,0.5],[0.7,0.1]])\n",
    "z = np.array([[0.24,0.55],[0.35,0.6]])\n",
    "\n",
    "inputs = np.array([0.5, 0.1])\n",
    "target = np.array([0.1, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update randomised inputs to fixed inputs\n",
    "weights[0][0] = x\n",
    "weights[1][0] = y\n",
    "weights[2][0] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = forward_pass(weights[0][0], inputs)\n",
    "h2 = forward_pass(weights[1][0], h1)\n",
    "#output\n",
    "outputs = forward_pass(weights[2][0], h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02421  , 0.0300925])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the backward pass outputs\n",
    "def out_gradient(target, output, inputs):\n",
    "    gradient = -(target - output)*inputs\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04175, 0.0258 ])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1 , 0.99])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00316423, -0.00195538],\n",
       "       [-0.04007614, -0.02476561]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = [out_gradient(target, outputs, item) for item in h2]\n",
    "#output gradients\n",
    "gradients = np.vstack(grad).T\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hid_gradient(target, output, inputs, weight, neurons):\n",
    "    neuron = []\n",
    "    for i in range(len(output)):\n",
    "        s_o = -(target[i] - output[i])\n",
    "        k = s_o*weight[:, neurons][i]\n",
    "        neuron.append(k)\n",
    "    out = np.sum(neuron)*inputs\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00885393, -0.02939505],\n",
       "       [-0.01544073, -0.05126321]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden_two = 2\n",
    "w = weights[2][0]\n",
    "mygrads = []\n",
    "for neuron in range(n_hidden_two):\n",
    "    grad = np.array([hid_gradient(target, outputs, myinputs, w , neuron) for myinputs in h1])\n",
    "    mygrads.append(grad)\n",
    "mygrads = np.vstack(mygrads)\n",
    "mygrads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hid_two_layer(target, outputs, inputs, w1, neuron, w2):\n",
    "    mygrads = []\n",
    "    for i in range(len(w1)):\n",
    "        grad = hid_gradient(target, outputs, w1[:,neuron][i], w2,i)\n",
    "        mygrads.append(grad)\n",
    "    xsum = np.sum(mygrads)*inputs\n",
    "    return xsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21794094, -0.04358819],\n",
       "       [-0.11942076, -0.02388415]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden_two = 2\n",
    "h2_mygrads = []\n",
    "w1 = weights[1][0]\n",
    "w2 = weights[2][0]\n",
    "for neuron in range(n_hidden_two):\n",
    "    grad = np.array([hid_two_layer(target, outputs, myinputs, w1, neuron, w2) for myinputs in inputs])\n",
    "    h2_mygrads.append(grad)\n",
    "h2_mygrads = np.vstack(h2_mygrads)\n",
    "h2_mygrads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the learning rate\n",
    "#update weights\n",
    "l = 0.5\n",
    "weights[0][0] = weights[0][0] - l*h2_mygrads\n",
    "weights[1][0] = weights[1][0] - l*mygrads\n",
    "weights[2][0] = weights[2][0] - l*gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[0.11897047, 0.22179409],\n",
       "         [0.20971038, 0.09194208]])], [array([[0.01442697, 0.51469752],\n",
       "         [0.70772036, 0.1256316 ]])], [array([[0.24158212, 0.55097769],\n",
       "         [0.37003807, 0.61238281]])]]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24158212, 0.55097769],\n",
       "       [0.37003807, 0.61238281]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialze_network(n_input, n_hidden, n_output):\n",
    "    network = []\n",
    "    hidden_layer = {'weights': [np.random.rand(n_input,n_hidden)]}\n",
    "    network.append(hidden_layer)\n",
    "    hidden_layer = {'weights': [np.random.rand(n_input,n_hidden)]}\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = {'weights': [np.random.rand(n_hidden,n_output)]}\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "#forward pass\n",
    "#defines sigmoid function\n",
    "def sigmoid(x):\n",
    "    s = 1/(1 + np.exp(-x))\n",
    "    return s\n",
    "#derivative of the loss function delta rule\n",
    "def dloss(target, output):\n",
    "    error = -(target - output)\n",
    "    return error\n",
    "#forward pass\n",
    "def forward_pass(weights, inputs):\n",
    "    a = np.dot(weights, inputs)\n",
    "    return a\n",
    "def out_gradient(target, output, inputs):\n",
    "    gradient = -(target - output)*inputs\n",
    "    return gradient\n",
    "\n",
    "#onehidden layers\n",
    "def hid_gradient(target, output, inputs, weight, neurons):\n",
    "    neuron = []\n",
    "    for i in range(weight.shape[1]):\n",
    "        s_o = -(target - output)\n",
    "        k = s_o*weight[:, neurons][i]\n",
    "        neuron.append(k)\n",
    "    out = np.sum(neuron)*inputs\n",
    "    return out\n",
    "def hid_two_layer(target, outputs, inputs, w1, neuron, w2):\n",
    "    mygrads = []\n",
    "    for i in range(len(w1)):\n",
    "        grad = hid_gradient(target, outputs, w1[:,neuron][i], w2,i)\n",
    "        mygrads.append(grad)\n",
    "    xsum = np.sum(mygrads)*inputs\n",
    "    return xsum\n",
    "\n",
    "#loss function\n",
    "def lossfunction(target,output):\n",
    "    loss = (1/2)*(target - output)**2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(network, inputs, target, l, n_epoch):\n",
    "    weights = [neuron['weights'] for neuron in network]\n",
    "    for epoch in range(n_epoch):\n",
    "        myloss = []\n",
    "        mygrads = []\n",
    "        h2_mygrads = []\n",
    "        for i in range(len(inputs)):\n",
    "            h1 = forward_pass(weights[0][0][0], inputs[i])\n",
    "            h2 = forward_pass(weights[1][0], h1)\n",
    "            outputs = forward_pass(weights[2][0][0], h2)\n",
    "            loss = lossfunction(target[i], outputs)\n",
    "            t_loss = np.sum(loss)\n",
    "            myloss.append(t_loss)\n",
    "            grad = [out_gradient(target[i], outputs, item) for item in h2]\n",
    "            #print(\"this is output gradient {} for iteration {}\".format(grad, i))\n",
    "            gradients = np.vstack(grad).T     #output gradients\n",
    "            n_hidden_two = 2\n",
    "            w = weights[2][0]\n",
    "            #hidden layer two\n",
    "            for neuron in range(n_hidden_two):\n",
    "                grad = np.array([hid_gradient(target, outputs, myinputs,weights[2][0] , neuron) for myinputs in h1])\n",
    "            mygrads.append(grad)\n",
    "            mygrads = np.vstack(mygrads)\n",
    "            #hidden layer one\n",
    "            n_hidden_two = 2\n",
    "            w1 = weights[1][0]\n",
    "            w2 = weights[2][0]\n",
    "            for neuron in range(n_hidden_two):\n",
    "                grad = np.array([hid_two_layer(target, outputs, myinputs, w1, neuron, w2) for myinputs in inputs[i]])\n",
    "            h2_mygrads.append(grad)\n",
    "            h2_mygrads = np.vstack(h2_mygrads)\n",
    "            weights[0][0] = weights[0][0] - l*h2_mygrads\n",
    "            weights[1][0] = weights[1][0] - l*mygrads\n",
    "            weights[2][0][0] = weights[2][0][0] - l*gradients\n",
    "            final_loss = np.sum(myloss)\n",
    "            #print('>epoch={}, error={}'.format(n_epoch, final_loss))\n",
    "            return final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training samples\n",
    "inputs = np.array([[2.7810836, 2.550537003], [1.465489372, 2.362125076], [396561688, 4.400293529], [1.38807019, 1.850220317],\n",
    "                  [3.06407232, 3.005305973],[7.627531214, 2.759262235],[5.332441248, 2.088626775],[6.922596716, 1.77106367],\n",
    "                  [8.675418651, 0.242068655], [7.673756466, 3.508563011]])\n",
    "target = np.array([[0], [0], [0], [0], [0], [1], [1], [1], [1], [1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset from:\n",
    "\n",
    "https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/\n",
    "\n",
    "An alternative implementation can also be accessed via this link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize network\n",
    "network = initialze_network(inputs.shape[1], 2, target.shape[1])\n",
    "weights = [neuron['weights'] for neuron in network]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weights': [array([[0.76235475, 0.61464184],\n",
       "          [0.3652777 , 0.60058028]]), array([0.01487713, 0.829767  ])]},\n",
       " {'weights': [array([[0.4104964 , 0.64708764],\n",
       "          [0.88038413, 0.86201736]]), array([0.27902185, 0.99723562])]},\n",
       " {'weights': [array([[0.70818411, 0.95309679],\n",
       "          [0.42618508, 0.11536369]]), array([0.08711459, 0.11089362])]}]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2][0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "myloss = []\n",
    "mygrads = []\n",
    "h2_mygrads = []\n",
    "h1 = forward_pass(weights[0][0], inputs[0])\n",
    "h2 = forward_pass(weights[1][0], h1)\n",
    "outputs = forward_pass(weights[2][0][0], h2)\n",
    "loss = lossfunction(target[0], outputs)\n",
    "t_loss = np.sum(loss)\n",
    "myloss.append(t_loss)\n",
    "grad = [out_gradient(target[0], outputs, item) for item in h2]\n",
    "#print(\"this is output gradient {} for iteration {}\".format(grad, i))\n",
    "gradients = np.vstack(grad).T     #output gradients\n",
    "n_hidden_two = 2\n",
    "w = weights[2][0]\n",
    "#hidden layer two\n",
    "for neuron in range(n_hidden_two):\n",
    "    grad = np.array([hid_gradient(target, outputs, myinputs, weights[2][0] , neuron) for myinputs in h1])\n",
    "mygrads.append(grad)\n",
    "mygrads = np.vstack(mygrads)\n",
    "#hidden layer one\n",
    "n_hidden_two = 2\n",
    "w1 = weights[1][0]\n",
    "w2 = weights[2][0]\n",
    "for neuron in range(n_hidden_two):\n",
    "    grad = np.array([hid_two_layer(target, outputs, myinputs, w1, neuron, w2) for myinputs in inputs[0]])\n",
    "h2_mygrads.append(grad)\n",
    "h2_mygrads = np.vstack(h2_mygrads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[272.95051203, 188.56241765]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mygrads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0][0] = weights[0][0] - l*h2_mygrads\n",
    "weights[1][0] = weights[1][0] - l*mygrads\n",
    "weights[2][0][0] = weights[2][0][0] - l*gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-158.66150571, -145.59328059],\n",
       "       [-159.05858275, -145.60734215]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23.48764147, 40.42477357]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.03563662, -19.25928999])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.03563662, -19.25928999],\n",
       "       [  0.42618508,   0.11536369]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-0bb4e9efc4a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmyloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-132-a6c9e906ee38>\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(network, inputs, target, l, n_epoch)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m#hidden layer two\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mneuron\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden_two\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                 \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhid_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyinputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mneuron\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmyinputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mh1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mmygrads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mmygrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmygrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "n_epoch = [x for x in range(1, 100)]\n",
    "loss = []\n",
    "for n in n_epoch:\n",
    "    myloss = train_network(network, inputs, target, 0.5, n)\n",
    "    loss.append(myloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network works as we see the decrease in the loss function with each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weights': [array([[0.94246795, 0.05119498],\n",
       "          [0.01348304, 0.04932447]])]},\n",
       " {'weights': [array([[0.11698036, 0.06007718],\n",
       "          [0.49238838, 0.31364219]])]},\n",
       " {'weights': [array([[0.10377062],\n",
       "          [0.31765897]])]}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weights[2][0].T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0.01,0.2],[0.15,0.08]])\n",
    "y = np.array([[0.01,0.5],[0.7,0.1]])\n",
    "z = np.array([[0.24,0.55]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24, 0.55]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
